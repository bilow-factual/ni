Command-line option parser.
A context-aware command line parser, which in a Canard-powered world works as
the reader. Certain static symbols, despite being resolved at runtime, have
read-time parse semantics that make it possible for ni syntax to be as
expressive as (and often much more than) nfu. See design/cli.md for details.

package ni;

A parse state is just a modified copy of @ARGV, including string
transformations. For example:

| $ ni foo m'r a + b' T4
  # initial parse state is ("foo", "mr a + b", "T4")
  # quasifile parse step consumes "foo", so we then have ("mr a + b", "T4")
  # quasifile parse step rejects ("mr a + b", "T4") by returning ()
  # long option parsers all reject ("mr a + b", "T4")
  # short option parser "m" happens:
  #   m -> ruby-code
  #   ruby-code is run on ("r a + b", "T4") and returns (code, "T4")
  #     (had the code ended in extra ] characters, the parser would have
  #      returned those separately, e.g. (code, "]", "T4"))
  # ...

This might seem like it would be slow, but most of the overhead lives in
high-throughput native functions that are unlikely to take up much time in
practice.

use constant end_of_argv  => sub {@_           ? () : (0)};
use constant consumed_opt => sub {length $_[0] ? () : @_};

sub seqr(\@) {my ($ps) = @_;
         sub {my ($x, @xs, @ys, @ps);
              (($x, @_) = &$_(@_)) ? push @xs, $x : return () for @ps = @$ps;
              (\@xs, @_)}}

sub altr(\@) {my ($ps) = @_;
         sub {my @ps, @r; @r = &$_(@_) and return @r for @ps = @$ps; ()}}

sub seq(@) {seqr @_}
sub alt(@) {altr @_}

sub rep($;$) {my ($p, $n) = (@_, 0);
         sub {my (@c, @r);
              push @r, $_ while ($_, @_) = &$p(@c = @_);
              @r >= $n ? (\@r, @c) : ()}}

sub maybe($) {my ($p) = @_;
         sub {my @xs = &$p(@_); @xs ? @xs : (undef, @_)}};

sub pmap(&$) {my ($f, $p) = @_;
         sub {my @xs = &$p(@_); @xs ? (&$f($_ = $xs[0]), @xs[1..$#xs]) : ()}}

sub pif(&$) {my ($f, $p) = @_;
        sub {my @xs = &$p(@_); @xs && &$f($_ = $xs[0]) ? @xs : ()}}

sub ptag($$) {my ($t, $p)  = @_; pmap {+{$t => $_}} $p}
sub pn($@)   {my ($n, @ps) = @_; pmap {$$_[$n]} seq @ps}

Match/consume regex.
You can specify a match group if you want to save (i.e. not consume) part of
the string. For example, to assert that `m` can be parsed only when followed
by one or more characters (but to leave those characters for the next parse
stage):

| seq mr('^m(.+)'), parse_the_grouped_stuff...

It's important to anchor the regex; otherwise the match could begin anywhere
within the first argument.

sub mr($) {my $r = qr/$_[0]/;
      sub {my ($x, @xs) = @_; $x =~ s/($r)/$2/ ? ($1, $x, @xs) : ()}}

sub mrc($) {pn 0, mr $_[0], maybe consumed_opt}

Character dispatch.
This is just a way to bypass a lot of the alt() overhead that would otherwise
result to decode a high-entropy stream of text. The most obvious case is short
option parsing.

| chalt(a => seq(...), b => ..., ...)
  # functionally the same as alt(pn(1, mr('^a', seq(...))),
  #                              pn(1, mr('^b', ...)),
  #                              ...)

Note that the dispatch character itself isn't encoded into the result.

sub chaltr(\%) {my ($ps) = @_;
           sub {my ($x, @xs, $c, @ys) = @_;
                return () unless $x =~ s/^(.)// && exists $$ps{$c = $1};
                (@ys = $$ps{$c}($x, @xs)) ? ($ys[0], @ys[1..$#ys]) : ()}}

sub chalt(%) {my %h = @_; chaltr %h}

Regex parsing.
Sometimes we'll have an operator that takes a regex, which is subject to the
CLI reader problem the same way code arguments are. Rather than try to infer
brackets the same way, we just require that regexes are terminated with /
(which should be ok because that's also how they typically start).

use constant regex => pmap {s/\/$//; $_} mr '^(?:[^\\/]|\\.)*/';

Code parsing.
This is nontrivial due to the CLI reader problem. The idea is that we need to
figure out how many closing brackets belong to the code, vs how many close a
lambda. Depending on the language, the only way to do this may be to shell out
to an interpreter.

use constant rbcode => sub {
  return @_ unless $_[0] =~ /\]$/;
  my ($code, @xs, $x, $qcode) = @_;
  ($qcode = $code) =~ s/'/'\\''/g;
  $x .= ']' while $_ = system("ruby -ce '$qcode' >/dev/null 2>&1")
                  and ($qcode =~ s/\]$//, $code =~ s/\]$//);
  $_ ? () : length $x ? ($code, $x, @xs) : ($code, @xs)};

Perl code is similar to Ruby, but we need to explicitly disable any BEGIN{}
blocks to avoid executing side effects. We can guarantee that nothing will run
(beyond `use` statements, which we assume are safe) by removing any
occurrences of the string `BEGIN` and replacing them with something
syntactically equivalent but less volatile -- in this case, `END`.

use constant plcode => sub {
  return @_ unless $_[0] =~ /\]$/;
  my ($code, @xs, $x, $qcode) = @_;
  ($qcode = $code) =~ s/'/'\\''/g;

  my $begin_warning = $qcode =~ s/BEGIN/END/g;
  $x .= ']' while $_ = system("perl -ce '$qcode' >/dev/null 2>&1")
                  and ($qcode =~ s/\]$//, $code =~ s/\]$//);

  print STDERR <<EOF if $_ && $begin_warning;
ni: failed to get closing bracket count for perl code "$_[0]", possibly
    because BEGIN-block metaprogramming is disabled when ni tries to figure
    this out.
    https://github.com/spencertipping/ni/tree/master/design/cli-reader-problem.md
EOF
  $_ ? () : length $x ? ($code, $x, @xs) : ($code, @xs)};

CLI option parsing.
%syntax_elements is an alias table so we can describe operator syntax using
just strings. %operator_syntax maps short operator letters to a parser for
their arguments (if any); for example:

| use constant takespec => mr '^\d+|^\+\d+';
  $operators{T} = pmap {"head -n$_"} takespec;

Quasifiles are parsed with early preference using subs from
@quasifile_parsers; functionally it's interpreted as a choice that happens
_before_ option parsing happens. This means that in the event of something
ambiguous, e.g. `ni f00`, where `f00` is the name of a file, the file
interpretation will be preferred. If you want to force the option
interpretation, you need to say `ni -f00` (provided that `-f00` isn't itself a
file).

our %operators;
our @quasifiles;

our %operator_docs;
our @quasifile_docs;
our %syntax_docs;

sub defop($%) {
  my ($op, %spec) = @_;
  exists $spec{$_} or die "defop $op: must specify key $_" for qw/doc syntax/;
  $operators{$op}     = $spec{syntax};
  $operator_docs{$op} = $spec{doc};
}

sub defqfile(%) {
  my (%spec) = @_;
  exists $spec{$_} or die "defqfile: must specify key $_" for qw/doc syntax/;
  unshift @quasifiles,     $spec{syntax};
  unshift @quasifile_docs, $spec{doc};
}

sub defsyntax($%) {
  my ($name, %spec) = @_;
  exists $spec{$_} or die "defsyntax: must specify key $_" for qw/doc/;
  $syntax_docs{$name} = $spec{doc};
}

I define the toplevel parser to be self-referential for the moment. Later when
we `use constant` the outer function will be replaced with the real one,
resulting in the inner `opts(@_)` call pointing to it. (The indirection is
required, unfortunately; otherwise we'd be unable to change the reference
later from underneath the `use constant` expression.)

sub ops() {sub {ops()->(@_)}}

CLI syntax elements.
Building blocks for ni's command-line grammar, and the toplevel parser. See
below for documentation.

TODO: refactor the below into "read-only", "pipe", "read-write", "write-only",
etc -- basically, a lot of elements below should be stream-context-aware. The
erroneous use of "ilist" as a data source should make this obvious.

use constant quasifile  => altr @quasifiles;
use constant short      => chaltr %operators;
use constant list       => pn 1, mrc '^\[', ops, mrc '^\]';
use constant ilist      => rep short, 1;
use constant datasource => alt quasifile, list, ilist;
use constant op         => pn 1, rep(consumed_opt),
                                 alt(quasifile, short),
                                 rep(consumed_opt);
use constant ops        => rep op;
use constant cli        => pn 0, ops, end_of_argv;

defsyntax 'quasifile', doc => <<'EOF';
Quasifile syntax element
Delegates to all known quasifile parsers. You can define a new one using the
`defqfile` function; for example:

  # mrc = match regex and consume empty argument
  defqfile doc => <<'EOF', syntax => pmap {"cat $_"} pif {-r} mrc('^[^]]+');
  Regular file matcher
  Matches files that exist and are readable.
  EOF
EOF

defsyntax 'short', doc => <<'EOF';
Short operator element
Delegates to all known short-form operators. You can define a new one using
the `defop` function:

  defop 'g', doc => <<'EOF', syntax => pmap {"sort $_"} maybe colspec;
  Group operator
  Takes an optional column spec and sorts its input.
  EOF
EOF

defsyntax 'list', doc => <<'EOF';
List element
Contains a stream transformer and represents it as an object. ni uses these as
lambda expressions. Lists are encased in square brackets, which need not be
whitespace-separated from their contents:

  $ ni data1 jidata2                    # join against a qfile directly
  $ ni data1 ji[data2 m'r b, a']        # join against a lambda output
EOF

defsyntax 'ilist', doc => <<'EOF';
Implied list element
This is used by commands that expect a lambda but have no reason to make you
write brackets. For example, hadoop and variants:

  $ ni hdfs:/path h[m'b, a']            # explicit lambda
  $ ni hdfs:/path hm'b, a'              # implied lambda (h coerces it)
EOF

defsyntax 'datasource', doc => <<'EOF';
Data source element
Anything that can be read in isolation (i.e. without sending data into it).
Can be a quasifile, a list, or an implied list, in that order of preference.
Note that data sources aren't inferred at the toplevel; this element is used
by operators that consume data.
EOF

defsyntax 'op', doc => <<'EOF';
Stream operator element
Anything that can be appended to an existing pipeline, which ends up being a
readable quasifile or a short operator. Consumes empty arguments on either
side. For example:

  #    |-----------| |--------| <- these are both ops
  $ ni /path/to/data m'r a + b'
EOF
